# 社区问题交流总结

## TFS
> 淘宝tfs相关交流总结.


### 运行问题 

#### "block: 34754 has been lost, do not replicate" 频繁报错，集群没有自动修复缺失块信息
> 修复block时所选源异常导致修复任务一直失败，通过admintool 干预修复所选源规避问题

#### 单集群, ns, ds 服务正常但Nameserver服务总是一段时间后退出
> keepalived 的日志显示，内网不稳定, vip 频繁漂移, 有部分阶段 两台ns都认为自己是master, 其中一台自动退出


#### 单集群, ns, ds 服务正常但Nameserver服务总是read only
> ns 服务没有识别出配置的vip,  在keepalived.conf 配置中给vip  配置的网卡打上标签， ns 能识别出vip 就ok了

### faq

#### 有哪些途径可以获取更多的TFS资料?
* [项目官网](http://tfs.taobao.org/)
* [张友东博客](http://blog.yunnotes.net/index.php/tfs_summary/)
* [淘宝旺旺群-TFS开源用户交流群](群号:  96313980)
* [QQ群1-淘宝TFS交流群](群号:  239385249)
* [QQ群2-云存储技术交流](群号:  498739450)

#### 想确认下，针对ds，必须给它的数据目录mount到新的磁盘吗？
> 目录所在分区空间够用就可以用目录代替的;

#### 小集群(ds节点比较少), 怎么提高可接收的并发写请求, 而不会导致大量的写请求失败?
> TFS 2.2.16 版本里，写请求量比较大时会因为写冲突, 引发较多写失败，通过增加 ns.conf 中max_write_filecount 的配置值可以提高并发量
> 这个值是tfs控制对单块数据盘并发写入允许的上限，集群规模越大，值可以设置较小，集群较小时调大可以支持更高的并发.

### 2.2.16 的版本能不能强制升级到2.6 ?
> tfs-2.6 和 2.2 在块上组织数据的格式不一样，不能通过升级程序直接使用2.2的集群.

### 2.2.16 的版本是否支持多集群？
> 支持一主多备的部署方式

### 2.2.16 的版本是否主备集群扩容时是否支持不一样的机器或型号？
> 主备集群支持不通的机器数，即使同一集群内ds机器型号也可以不一样(为运维管理方便建议如硬盘数、硬盘大小差别不要太大)


### 2.2, 2.6 多副本是怎么分发的?
> client(sdk) 提交到 master ds 后 有master ds 负责剩余副本分发.


### TFS 可以配置在公网上吗?
> 基本没有权限验证这块，不建议。如果仅为调试方便需要ns和ds 都需要可以访问(配置nginx-tfs的话只需要nginx-tfs的部署服务器可访问)

### TFS 可以实现机柜安全吗?
> 可以，需要配置支持。ns 用 ns.conf 配置中的 group_mask 和 ds 的ip 做掩码运算得到相同值的ds视为同一机柜, 2.6 版本在ds.conf 引入rack_id 主动配置机柜信息的方案更简洁可考虑迁移该特性.


### 调用savefile()往tfs服务器上传图片的时候，怎么才能得到这个图片的url呢？
> 用http 的方式访问 tfs 你需要 部署 nginx-tfs, uri 涉及可参见文档  https://github.com/alibaba/nginx-tfs/blob/master/TFS_RESTful_API.markdown


### 部署nginx-tfs后，uri访问资源时为什么这个一定要输入一个V1?
> 代码写死， 支持两种v1, v2; v1 适用于只部署ns,ds 的情况，v2 使用于额外还部署了rcserver的情况.

### tfs_tool put 文件时输出的日志里有个size字段的值，这个值为什么有的是0, 有的非0?
> put 操作对应几个子操作，只有上传阶段的子操作size 字段的日志才有意义.

### 我怎么确认Nameserver 的HA部署成功?
> 第一个条件 grep role nameserver.log, 看到 master 字段时说明成功了，两个若都是slave 则表明不成功. 第二个条件主动关闭master 机器的nameserver服务，另一台的日志里 可以看到升级为master的日志. 具备这两个条件可以算是部署成功.



### 请问如下日志是什么意思?
```
[2015-10-27 15:30:13] INFO  layout_manager.cpp:630 [140170928482048] emergency_replicate_queue: 0, need: 6
[2015-10-27 15:30:13] INFO  layout_manager.cpp:717 [140170844575488] need: 6, source : 0, target: 0, percent: 1.995430e-01
```
> emergency_replicate_queue: 0, —> 检查出的丢失部分副本的块个数， need: 6 －－》 当前有多少没有做维护任务的机器   percent: 1.995430e-01 ->集群使用容量比

### 如下错误日志是什么意思?
```
[2015-10-27 13:37:46] ERROR write_raw_data (dataservice.cpp:2346) write data batch fail, blockid: 41983, ret: -24, error code: -24
```
> 文件句柄用完

### tfs 一般有哪些自维护任务？
> 副本修复，容量均衡，块压缩 等，默认一般开启

### tfs 什么情况下会丢失数据(覆盖)?
> 根据当前的实现一般出现丢失数据的同时也会发生数据覆盖(即tfs前后产生重名文件), 一般出现在如下情况
   * 代码bug-2.2.16 有一处bug(块在做迁移时没有控制写入，迁移过程块有一定概率写入文件并在后来被覆盖).
   * 硬盘没有断电保护的情况禁用barrier=0(索引更新内容丢失造成seq值会退)


### 有个问题想咨询下，就是我用TFS(nginx-tfs0， 读取服务器不存在的图片， 在浏览器上会随机显示一张其他图片， 不知道大家有没有碰到过这个问题?
> 不能重现。

### TFS 通过版本去控制并发，能不能说一下如何解决冲突的?以及发生冲突后他都做了什么，会不会有其他副作用?
> 修改请求发起时会从ns 获取一个版本号, tfs 在修改请求的不同阶段检查这个版本号与当前block最新的版本号是否一致，若不一致驳回修改请求(修改失败).
